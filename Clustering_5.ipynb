{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?\n",
        "\n",
        "Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in\n",
        "certain situations?\n",
        "\n",
        "Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically\n",
        "used to evaluate the performance of language models?\n",
        "\n",
        "Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an\n",
        "extrinsic measure?\n",
        "\n",
        "Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify\n",
        "strengths and weaknesses of a model?\n",
        "\n",
        "Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised\n",
        "learning algorithms, and how can they be interpreted?\n",
        "\n",
        "Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and\n",
        "how can these limitations be addressed?"
      ],
      "metadata": {
        "id": "qAAQlFkEsrm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the answers to your questions:\n",
        "\n",
        "1. A contingency matrix is a table used to evaluate the performance of a classification model by comparing predicted classes against actual classes. It helps calculate metrics like accuracy, precision, recall, and F1-score.\n",
        "\n",
        "2. A pair confusion matrix is a variant of the regular confusion matrix, where each entry represents the number of pairs of samples that are correctly or incorrectly classified. It's useful when evaluating models that predict multiple labels or classes.\n",
        "\n",
        "3. An extrinsic measure in NLP evaluates a language model's performance based on its ability to perform a specific task, such as sentiment analysis or machine translation. Examples include BLEU score, ROUGE score, and METEOR score.\n",
        "\n",
        "4. An intrinsic measure evaluates a model's performance based on its internal characteristics, such as clustering quality or dimensionality reduction. It differs from extrinsic measures, which focus on external tasks.\n",
        "\n",
        "5. A confusion matrix helps identify strengths and weaknesses of a model by visualizing correct and incorrect predictions. It's useful for understanding errors, precision, recall, and accuracy.\n",
        "\n",
        "6. Common intrinsic measures for unsupervised learning include:\n",
        "    - Silhouette Coefficient (clustering quality)\n",
        "    - Calinski-Harabasz Index (clustering quality)\n",
        "    - Davies-Bouldin Index (clustering quality)\n",
        "    - Principal Component Analysis (PCA) score (dimensionality reduction)\n",
        "\n",
        "These measures help evaluate clustering quality, separation, and compactness.\n",
        "\n",
        "7. Limitations of using accuracy as a sole evaluation metric include:\n",
        "    - Ignoring class imbalance issues\n",
        "    - Failing to account for false positives and false negatives\n",
        "    - Not considering precision and recall\n",
        "To address these limitations, use additional metrics like F1-score, precision, recall, and ROC-AUC score to get a more comprehensive understanding of the model's performance."
      ],
      "metadata": {
        "id": "Cm_NU_Qrszhq"
      }
    }
  ]
}