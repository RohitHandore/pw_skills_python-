{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To achieve the tasks outlined in the questions, we can use a combination of web scraping techniques. The Python libraries `requests`, `BeautifulSoup`, and `pandas` will be useful for this purpose. Below are the Python programs to extract the required information from the given YouTube channel URL.\n",
        "\n",
        "### Prerequisites\n",
        "Make sure you have the following libraries installed:\n",
        "```bash\n",
        "pip install requests beautifulsoup4 pandas\n",
        "```\n",
        "\n",
        "### Python Programs for Each Task\n",
        "\n",
        "#### Q1. Extract the video URL of the first five videos.\n",
        "\n",
        "```python\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find all video links\n",
        "video_links = soup.find_all('a', id='video-title', limit=5)\n",
        "\n",
        "# Extract URLs of the first five videos\n",
        "video_urls = [\"https://www.youtube.com\" + video['href'] for video in video_links]\n",
        "\n",
        "print(\"Video URLs:\", video_urls)\n",
        "```\n",
        "\n",
        "#### Q2. Extract the URL of the video thumbnails of the first five videos.\n",
        "\n",
        "```python\n",
        "# Find all thumbnail links\n",
        "thumbnails = soup.find_all('img', {'id': 'img'}, limit=5)\n",
        "\n",
        "# Extract thumbnail URLs of the first five videos\n",
        "thumbnail_urls = [thumb['src'] for thumb in thumbnails]\n",
        "\n",
        "print(\"Thumbnail URLs:\", thumbnail_urls)\n",
        "```\n",
        "\n",
        "#### Q3. Extract the title of the first five videos.\n",
        "\n",
        "```python\n",
        "# Extract titles of the first five videos\n",
        "video_titles = [video['title'] for video in video_links]\n",
        "\n",
        "print(\"Video Titles:\", video_titles)\n",
        "```\n",
        "\n",
        "#### Q4. Extract the number of views of the first five videos.\n",
        "\n",
        "```python\n",
        "# Find all view counts\n",
        "views = soup.find_all('span', class_='style-scope ytd-grid-video-renderer', limit=10)\n",
        "\n",
        "# Extract view counts of the first five videos (skipping non-view count spans)\n",
        "view_counts = [views[i].text for i in range(1, len(views), 2)][:5]\n",
        "\n",
        "print(\"View Counts:\", view_counts)\n",
        "```\n",
        "\n",
        "#### Q5. Extract the time of posting of the first five videos.\n",
        "\n",
        "```python\n",
        "# Extract the posting times of the first five videos (skipping non-time spans)\n",
        "posting_times = [views[i].text for i in range(0, len(views), 2)][:5]\n",
        "\n",
        "print(\"Posting Times:\", posting_times)\n",
        "```\n",
        "\n",
        "#### Save all the data scraped in the above questions in a CSV file.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Combine all the extracted data into a DataFrame\n",
        "data = {\n",
        "    \"Video URL\": video_urls,\n",
        "    \"Thumbnail URL\": thumbnail_urls,\n",
        "    \"Title\": video_titles,\n",
        "    \"Views\": view_counts,\n",
        "    \"Posted\": posting_times\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to a CSV file\n",
        "df.to_csv('youtube_videos.csv', index=False)\n",
        "\n",
        "print(\"Data saved to youtube_videos.csv\")\n",
        "```\n",
        "\n",
        "### Complete Code\n",
        "\n",
        "Combining all the above snippets into a complete code:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Extract video URLs\n",
        "video_links = soup.find_all('a', id='video-title', limit=5)\n",
        "video_urls = [\"https://www.youtube.com\" + video['href'] for video in video_links]\n",
        "\n",
        "# Extract thumbnail URLs\n",
        "thumbnails = soup.find_all('img', {'id': 'img'}, limit=5)\n",
        "thumbnail_urls = [thumb['src'] for thumb in thumbnails]\n",
        "\n",
        "# Extract titles\n",
        "video_titles = [video['title'] for video in video_links]\n",
        "\n",
        "# Extract views and posting times\n",
        "views = soup.find_all('span', class_='style-scope ytd-grid-video-renderer', limit=10)\n",
        "view_counts = [views[i].text for i in range(1, len(views), 2)][:5]\n",
        "posting_times = [views[i].text for i in range(0, len(views), 2)][:5]\n",
        "\n",
        "# Combine data into a DataFrame\n",
        "data = {\n",
        "    \"Video URL\": video_urls,\n",
        "    \"Thumbnail URL\": thumbnail_urls,\n",
        "    \"Title\": video_titles,\n",
        "    \"Views\": view_counts,\n",
        "    \"Posted\": posting_times\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save to CSV file\n",
        "df.to_csv('youtube_videos.csv', index=False)\n",
        "\n",
        "print(\"Data saved to youtube_videos.csv\")\n",
        "```\n",
        "\n",
        "Run the complete code in a Python environment to scrape the data from the given YouTube channel and save it into a CSV file. Make sure to adjust the scraping logic if the structure of the YouTube page changes."
      ],
      "metadata": {
        "id": "2bKxmFJw_hAL"
      }
    }
  ]
}