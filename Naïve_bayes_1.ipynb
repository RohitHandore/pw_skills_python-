{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Bayes' theorem?\n",
        "\n",
        "Q2. What is the formula for Bayes' theorem?\n",
        "\n",
        "Q3. How is Bayes' theorem used in practice?\n",
        "\n",
        "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
        "\n",
        "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
        "\n",
        "Q6. Assignment:\n",
        "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
        "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
        "each feature value for each class:\n",
        "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
        "A 3 3 4 4 3 3 3\n",
        "B 2 2 1 2 2 2 3\n",
        "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
        "to belong to?"
      ],
      "metadata": {
        "id": "FLWygKEsAZlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the answers to your questions:\n",
        "\n",
        "Q1. Bayes' theorem is a fundamental concept in probability theory that describes how to update the probability of a hypothesis (H) given new evidence (E). It provides a mathematical framework for making probabilistic predictions or diagnoses based on prior knowledge and new data.\n",
        "\n",
        "Q2. The formula for Bayes' theorem is:\n",
        "\n",
        "P(H|E) = P(E|H) * P(H) / P(E)\n",
        "\n",
        "Where:\n",
        "\n",
        "- P(H|E) is the posterior probability of the hypothesis (H) given the evidence (E)\n",
        "- P(E|H) is the likelihood of the evidence (E) given the hypothesis (H)\n",
        "- P(H) is the prior probability of the hypothesis (H)\n",
        "- P(E) is the probability of the evidence (E)\n",
        "\n",
        "Q3. Bayes' theorem is used in practice in various fields such as:\n",
        "\n",
        "- Machine learning (e.g., Naive Bayes classifier)\n",
        "- Medical diagnosis\n",
        "- Risk analysis\n",
        "- Quality control\n",
        "- Predictive maintenance\n",
        "\n",
        "It helps update probabilities based on new data, making it a powerful tool for decision-making under uncertainty.\n",
        "\n",
        "Q4. Bayes' theorem is closely related to conditional probability, as it provides a way to update conditional probabilities based on new evidence. The formula for Bayes' theorem can be seen as a way to compute the conditional probability P(H|E) given the likelihood P(E|H) and the prior probability P(H).\n",
        "\n",
        "Q5. When choosing a Naive Bayes classifier, consider the type of features and the relationship between them:\n",
        "\n",
        "- Multinomial Naive Bayes: use for categorical features with multiple classes\n",
        "- Bernoulli Naive Bayes: use for binary features\n",
        "- Gaussian Naive Bayes: use for continuous features with normal distributions\n",
        "\n",
        "Also, consider the size and complexity of the dataset, as well as the computational resources available. In general, Naive Bayes classifiers are suitable for small to medium-sized datasets with relatively simple relationships between features."
      ],
      "metadata": {
        "id": "8cxriqnLAtJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6 To solve this problem, we need to calculate the posterior probability of each class given the features X1 = 3 and X2 = 4.\n",
        "\n",
        "Using the Bayes formula:\n",
        "\n",
        "P(Class|X1, X2) = P(X1, X2|Class) * P(Class) / P(X1, X2)\n",
        "\n",
        "Since we have equal prior probabilities for each class, P(Class) = 0.5 for both classes A and B.\n",
        "\n",
        "We need to calculate P(X1, X2|Class) for each class:\n",
        "\n",
        "For Class A:\n",
        "P(X1=3|A) = 4/10 (from the table)\n",
        "P(X2=4|A) = 3/10 (from the table)\n",
        "Assuming independence, P(X1=3, X2=4|A) = P(X1=3|A) * P(X2=4|A) = 4/10 * 3/10 = 12/100\n",
        "\n",
        "For Class B:\n",
        "P(X1=3|B) = 1/10 (from the table)\n",
        "P(X2=4|B) = 3/10 (from the table)\n",
        "Assuming independence, P(X1=3, X2=4|B) = P(X1=3|B) * P(X2=4|B) = 1/10 * 3/10 = 3/100\n",
        "\n",
        "Now, we can calculate the posterior probabilities:\n",
        "\n",
        "P(A|X1=3, X2=4) = P(X1=3, X2=4|A) * P(A) / P(X1=3, X2=4) = 12/100 * 0.5 / P(X1=3, X2=4)\n",
        "P(B|X1=3, X2=4) = P(X1=3, X2=4|B) * P(B) / P(X1=3, X2=4) = 3/100 * 0.5 / P(X1=3, X2=4)\n",
        "\n",
        "Since P(A|X1=3, X2=4) > P(B|X1=3, X2=4), Naive Bayes would predict the new instance to belong to Class A."
      ],
      "metadata": {
        "id": "0E-rkCQnAlHZ"
      }
    }
  ]
}