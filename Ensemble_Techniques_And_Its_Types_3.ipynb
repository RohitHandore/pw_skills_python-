{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Random Forest Regressor?\n",
        "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
        "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
        "Q4. What are the hyperparameters of Random Forest Regressor?\n",
        "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
        "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
        "Q7. What is the output of Random Forest Regressor?\n",
        "Q8. Can Random Forest Regressor be used for classification tasks?"
      ],
      "metadata": {
        "id": "pI_Tgfov2VHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the answers to your questions:\n",
        "\n",
        "Q1. Random Forest Regressor is an ensemble learning algorithm that combines multiple decision trees to predict continuous outcomes. It is a type of supervised learning algorithm that can be used for regression tasks.\n",
        "\n",
        "Q2. Random Forest Regressor reduces the risk of overfitting by:\n",
        "- Using multiple decision trees, each trained on a random subset of the data\n",
        "- Averaging the predictions of the individual trees\n",
        "- Reducing the correlation between the trees\n",
        "\n",
        "Q3. Random Forest Regressor aggregates the predictions of multiple decision trees by:\n",
        "- Training each tree on a random subset of the data\n",
        "- Predicting the target variable for each tree\n",
        "- Averaging the predictions of all the trees\n",
        "\n",
        "Q4. The hyperparameters of Random Forest Regressor include:\n",
        "- Number of trees (n_estimators)\n",
        "- Maximum depth of each tree (max_depth)\n",
        "- Minimum number of samples required to split an internal node (min_samples_split)\n",
        "- Minimum number of samples required to be at a leaf node (min_samples_leaf)\n",
        "- Maximum number of features to consider at each split (max_features)\n",
        "\n",
        "Q5. The main difference between Random Forest Regressor and Decision Tree Regressor is that Random Forest Regressor combines multiple decision trees, while Decision Tree Regressor uses a single tree.\n",
        "\n",
        "Q6. Advantages of Random Forest Regressor:\n",
        "- Reduces overfitting\n",
        "- Handles high-dimensional data\n",
        "- Handles missing values\n",
        "- Fast and efficient\n",
        "Disadvantages:\n",
        "- Computationally expensive\n",
        "- Hyperparameter tuning required\n",
        "\n",
        "Q7. The output of Random Forest Regressor is a continuous value, representing the predicted target variable.\n",
        "\n",
        "Q8. No, Random Forest Regressor is designed for regression tasks and cannot be used for classification tasks directly. However, it can be used for classification tasks by using a classification metric (e.g., log loss) and modifying the output to predict probabilities."
      ],
      "metadata": {
        "id": "lsEqEfYp2YGv"
      }
    }
  ]
}